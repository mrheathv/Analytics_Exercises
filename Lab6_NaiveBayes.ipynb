{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Naive Bayes Classifier (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Loan Acceptance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the universalbank.csv again for this assignemnt. \n",
    "\n",
    "The file universalbank.csv contains data on 5000 customers of Universal Bank. The data include customer demographic information (age, income, etc.), the customerâ€™s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign. In this exercise, we focus on three predictors: age, income, experience, and the outcome Personal Loan.\n",
    "\n",
    "Partition the data into training (60%) and validation (40%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Experience  Income  Personal Loan\n",
      "0   25           1      49              0\n",
      "1   45          19      34              0\n",
      "2   39          15      11              0\n",
      "3   35           9     100              0\n",
      "4   35           8      45              0\n",
      "(5000, 4)\n",
      "Age              5000\n",
      "Experience       5000\n",
      "Income           5000\n",
      "Personal Loan    5000\n",
      "dtype: int64\n",
      "               Age   Experience       Income  Personal Loan\n",
      "count  5000.000000  5000.000000  5000.000000    5000.000000\n",
      "mean     45.338400    20.104600    73.774200       0.096000\n",
      "std      11.463166    11.467954    46.033729       0.294621\n",
      "min      23.000000    -3.000000     8.000000       0.000000\n",
      "25%      35.000000    10.000000    39.000000       0.000000\n",
      "50%      45.000000    20.000000    64.000000       0.000000\n",
      "75%      55.000000    30.000000    98.000000       0.000000\n",
      "max      67.000000    43.000000   224.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the data into band_df dataframe bank_df\n",
    "# Only keep the columns we need: Income, Experience, Age, Personal Loan.Drop the rest.\n",
    "bank_df=pd.read_csv(\"universalbank.csv\")\n",
    "\n",
    "bank_df = bank_df.drop(['ID', 'ZIP Code', 'Family', 'CCAvg', 'CD Account','Online','Education','Securities Account','CreditCard','Mortgage'], axis=1)\n",
    "\n",
    "# Use critical functions to explore the dataframe using print() to show results\n",
    "\n",
    "print(bank_df.head())\n",
    "print(bank_df.shape)\n",
    "print(bank_df.count())\n",
    "print(bank_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Experience  Income  Personal Loan\n",
      "0   25           1      49              0\n",
      "1   45          19      34              0\n",
      "2   39          15      11              0\n",
      "3   35           9     100              0\n",
      "4   35           8      45              0\n",
      "(5000, 4)\n",
      "Age              5000\n",
      "Experience       5000\n",
      "Income           5000\n",
      "Personal Loan    5000\n",
      "dtype: int64\n",
      "               Age   Experience       Income  Personal Loan\n",
      "count  5000.000000  5000.000000  5000.000000    5000.000000\n",
      "mean     45.338400    20.119600    73.774200       0.096000\n",
      "std      11.463166    11.440484    46.033729       0.294621\n",
      "min      23.000000     0.000000     8.000000       0.000000\n",
      "25%      35.000000    10.000000    39.000000       0.000000\n",
      "50%      45.000000    20.000000    64.000000       0.000000\n",
      "75%      55.000000    30.000000    98.000000       0.000000\n",
      "max      67.000000    43.000000   224.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Does the data needs further cleaning?\n",
    "# If you think so, write your clearning process here.\n",
    "#Somehow there's a negative value in experience, making it zero\n",
    "bank_df.Experience = np.where(bank_df.Experience < 0, 0,bank_df.Experience)\n",
    "\n",
    "\n",
    "print(bank_df.head())\n",
    "print(bank_df.shape)\n",
    "print(bank_df.count())\n",
    "print(bank_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (3000, 4) Validation Set: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_df, valid_df=train_test_split(bank_df, test_size = .4)\n",
    "print(\"Training Set:\", train_df.shape, \"Validation Set:\", valid_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Experience  Income\n",
      "2700   31           5      39\n",
      "648    50          25      34\n",
      "294    35           9      55\n",
      "2446   25           1      70\n",
      "950    32           6     112 \n",
      "       Age  Experience  Income\n",
      "490    34          10      90\n",
      "1555   59          33      49\n",
      "4163   54          28     108\n",
      "2490   52          28     168\n",
      "398    54          30      23\n"
     ]
    }
   ],
   "source": [
    "# Construct the model the perform analysis\n",
    "outcome = 'Personal Loan'\n",
    "X=list(train_df.columns)\n",
    "X.remove(outcome)\n",
    "\n",
    "train_X = train_df[X]\n",
    "valid_X = valid_df[X]\n",
    "train_y = train_df[outcome]\n",
    "valid_y = valid_df[outcome]\n",
    "\n",
    "print(train_X.head(), '\\n', valid_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Experience  Income             0             1  Predicted  \\\n",
      "490    34          10      90  4.716309e-03  9.952837e-01          1   \n",
      "1555   59          33      49  1.000000e+00  1.222940e-13          0   \n",
      "4163   54          28     108  9.987967e-01  1.203281e-03          0   \n",
      "2490   52          28     168  2.570972e-06  9.999974e-01          1   \n",
      "398    54          30      23  1.000000e+00  1.540208e-15          0   \n",
      "1909   56          30     101  9.999788e-01  2.121606e-05          0   \n",
      "3803   42          18      83  9.862212e-01  1.377878e-02          0   \n",
      "4251   42          16      62  9.999482e-01  5.183422e-05          0   \n",
      "957    56          32      88  9.999999e-01  1.454823e-07          0   \n",
      "3573   60          36     165  1.106244e-02  9.889376e-01          1   \n",
      "144    49          23      70  9.999991e-01  9.260773e-07          0   \n",
      "4052   43          19      54  9.999993e-01  6.641749e-07          0   \n",
      "3767   40          16      83  9.175547e-01  8.244529e-02          0   \n",
      "3065   39          15     121  3.216012e-05  9.999678e-01          1   \n",
      "4344   53          28     181  7.144347e-08  9.999999e-01          1   \n",
      "2223   53          28      74  1.000000e+00  4.864055e-08          0   \n",
      "1983   31           5      20  9.999969e-01  3.053256e-06          0   \n",
      "4351   30           3      32  9.994826e-01  5.174185e-04          0   \n",
      "4820   42          17      44  9.999999e-01  1.198667e-07          0   \n",
      "1013   39          13      58  9.997565e-01  2.434752e-04          0   \n",
      "813    50          25     130  3.300884e-02  9.669912e-01          1   \n",
      "2296   27           3      82  8.465002e-05  9.999153e-01          1   \n",
      "1027   32           7     108  1.703791e-06  9.999983e-01          1   \n",
      "868    40          15     161  2.007489e-10  1.000000e+00          1   \n",
      "1050   53          27     145  3.263527e-03  9.967365e-01          1   \n",
      "3319   60          35     153  2.265280e-01  7.734720e-01          1   \n",
      "3912   40          14      69  9.970652e-01  2.934800e-03          0   \n",
      "420    47          22      58  9.999999e-01  8.908234e-08          0   \n",
      "943    30           4      80  1.006415e-03  9.989936e-01          1   \n",
      "2283   54          28      79  9.999999e-01  1.452395e-07          0   \n",
      "\n",
      "      Personal Loan  \n",
      "490               0  \n",
      "1555              0  \n",
      "4163              1  \n",
      "2490              1  \n",
      "398               0  \n",
      "1909              0  \n",
      "3803              0  \n",
      "4251              0  \n",
      "957               0  \n",
      "3573              1  \n",
      "144               0  \n",
      "4052              0  \n",
      "3767              0  \n",
      "3065              0  \n",
      "4344              0  \n",
      "2223              0  \n",
      "1983              0  \n",
      "4351              0  \n",
      "4820              0  \n",
      "1013              0  \n",
      "813               1  \n",
      "2296              0  \n",
      "1027              0  \n",
      "868               0  \n",
      "1050              1  \n",
      "3319              1  \n",
      "3912              0  \n",
      "420               0  \n",
      "943               0  \n",
      "2283              0  \n"
     ]
    }
   ],
   "source": [
    "# Predict the classification for test dataset\n",
    "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
    "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side.\n",
    "\n",
    "mnomial = MultinomialNB()\n",
    "mnomial.fit(train_X, train_y)\n",
    "\n",
    "y_predict= mnomial.predict(valid_X)\n",
    "y_predProb= mnomial.predict_proba(valid_X)\n",
    "\n",
    "predicted = pd.concat([valid_X, pd.DataFrame(y_predProb, index = valid_X.index)], axis = 1)\n",
    "predicted = pd.concat([predicted, pd.DataFrame(y_predict, index = predicted.index, columns=[\"Predicted\"])], axis = 1)\n",
    "predicted = pd.concat([predicted, pd.DataFrame(valid_y, index = predicted.index)], axis = 1)\n",
    "\n",
    "print(predicted.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of your prediction against the observed outcome.\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_y,y_predict))\n",
    "\n",
    "# How well do you think the model does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "#Although it says the model is 78% accurate it doesn't appear to predict whether or not the individual will pursue a personal loan. \n",
    "# Lesson learned from this lab:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automobile Accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file accidents.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on three predictors: weather conditions (WEATHER_R), traffic conditions (TRAF_CON_R), and road type (INT_HWY).\n",
    "\n",
    "Our goal here is to predict whether an accident just reported will involve fatality (MAX_SEV_IR = 2), a non fetal injury (MAX_SEV_IR = 1) or not injury (MAX_SEV_IR = 0).\n",
    "\n",
    "Partition the data into training (80%) and validation (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT_HWY       42183\n",
      "TRAF_CON_R    42183\n",
      "WEATHER_R     42183\n",
      "MAX_SEV_IR    42183\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data into band_df dataframe accidents_df\n",
    "# Only keep the columns we need. Drop the rest.\n",
    "# Use critical functions to explore the dataframe using print() to show results\n",
    "accidents_df=pd.read_csv(\"accidents.csv\")\n",
    "accidents_df = accidents_df.drop([\n",
    "\n",
    "'HOUR_I_R',\n",
    "'ALCHL_I',\n",
    "'ALIGN_I',\n",
    "'STRATUM_R',\n",
    "'WRK_ZONE',\n",
    "'WKDY_I_R',\n",
    "'LGTCON_I_R',\n",
    "'MANCOL_I_R',\n",
    "'PED_ACC_R',\n",
    "'RELJCT_I_R',\n",
    "'REL_RWY_R',\n",
    "'PROFIL_I_R',\n",
    "'SPD_LIM',\n",
    "'SUR_COND',\n",
    "'TRAF_WAY',\n",
    "'VEH_INVL',\n",
    "'INJURY_CRASH',\n",
    "'NO_INJ_I',\n",
    "'PRPTYDMG_CRASH',\n",
    "'FATALITIES'\n",
    "], axis=1)\n",
    "\n",
    "print(accidents_df.count())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (33746, 4) Validation Set: (8437, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set: 80% training and 20% validation\n",
    "train_df, valid_df=train_test_split(accidents_df, test_size = .2)\n",
    "print(\"Training Set:\", train_df.shape, \"Validation Set:\", valid_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INT_HWY  TRAF_CON_R  WEATHER_R\n",
      "29653        0           2          1\n",
      "20141        0           0          1\n",
      "34385        0           0          1\n",
      "1548         0           2          1\n",
      "12238        0           0          1 \n",
      "        INT_HWY  TRAF_CON_R  WEATHER_R\n",
      "9078         0           0          1\n",
      "5959         0           1          1\n",
      "8928         0           0          1\n",
      "29814        0           0          1\n",
      "41861        0           0          1\n"
     ]
    }
   ],
   "source": [
    "# Construct the model the perform analysis\n",
    "outcome = 'MAX_SEV_IR'\n",
    "X=list(train_df.columns)\n",
    "X.remove(outcome)\n",
    "\n",
    "train_X = train_df[X]\n",
    "valid_X = valid_df[X]\n",
    "train_y = train_df[outcome]\n",
    "valid_y = valid_df[outcome]\n",
    "\n",
    "print(train_X.head(), '\\n', valid_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INT_HWY  TRAF_CON_R  WEATHER_R         0         1         2  \\\n",
      "9078         0           0          1  0.498756  0.489946  0.011298   \n",
      "5959         0           1          1  0.476460  0.514482  0.009057   \n",
      "8928         0           0          1  0.498756  0.489946  0.011298   \n",
      "29814        0           0          1  0.498756  0.489946  0.011298   \n",
      "41861        0           0          1  0.498756  0.489946  0.011298   \n",
      "...        ...         ...        ...       ...       ...       ...   \n",
      "19514        1           0          1  0.512589  0.470090  0.017321   \n",
      "36551        0           2          1  0.453950  0.538809  0.007242   \n",
      "35904        0           0          1  0.498756  0.489946  0.011298   \n",
      "35885        0           2          1  0.453950  0.538809  0.007242   \n",
      "39009        0           0          1  0.498756  0.489946  0.011298   \n",
      "\n",
      "       Predicted  MAX_SEV_IR  \n",
      "9078           0           0  \n",
      "5959           1           1  \n",
      "8928           0           0  \n",
      "29814          0           1  \n",
      "41861          0           1  \n",
      "...          ...         ...  \n",
      "19514          0           1  \n",
      "36551          1           0  \n",
      "35904          0           1  \n",
      "35885          1           1  \n",
      "39009          0           0  \n",
      "\n",
      "[8437 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict the classification for test dataset\n",
    "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
    "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side.\n",
    "\n",
    "mnomial = MultinomialNB()\n",
    "mnomial.fit(train_X, train_y)\n",
    "\n",
    "y_predict= mnomial.predict(valid_X)\n",
    "y_predProb= mnomial.predict_proba(valid_X)\n",
    "\n",
    "predicted = pd.concat([valid_X, pd.DataFrame(y_predProb, index = valid_X.index)], axis = 1)\n",
    "predicted = pd.concat([predicted, pd.DataFrame(y_predict, index = predicted.index, columns=[\"Predicted\"])], axis = 1)\n",
    "predicted = pd.concat([predicted, pd.DataFrame(valid_y, index = predicted.index)], axis = 1)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "# compute model accuracy of your prediction against observed outcomes.\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_y,y_predict))\n",
    "\n",
    "\n",
    "\n",
    "# How well do you think the model does?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Credit: Can you improve the accuracy of the model to above 0.08 by finding a different set of the predictors?\n",
    "# Show you model below:\n",
    "#'INJURY_CRASH' would certainly increase the prediction accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "#This model appears to more accurately pick if an accident will be fatal or not, compared to the personal loan predictions which were not as accurate. \n",
    "\n",
    "# Lesson learned from this lab:\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
